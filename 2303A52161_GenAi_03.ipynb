{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 166 iterations\n",
      "Minimum occurs at x = 1.5377093794492703e-05\n",
      "Minimum value = 10.000000000709365\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def f(x):\n",
    "    return 5 * x**4 + 3 * x**2 + 10\n",
    "def df(x):\n",
    "    return 20 * x**3 + 6 * x\n",
    "def gradient_descent(learning_rate, max_iterations):\n",
    "\n",
    "    x = 1.0\n",
    "    for i in range(max_iterations):\n",
    "        gradient = df(x)\n",
    "        prev_x = x\n",
    "        x = x - learning_rate * gradient\n",
    "\n",
    "        if abs(x - prev_x) < 1e-6:\n",
    "            print(f\"Converged after {i+1} iterations\")\n",
    "            break\n",
    "    return x\n",
    "learning_rate = 0.01\n",
    "max_iterations = 1000\n",
    "min_x = gradient_descent(learning_rate, max_iterations)\n",
    "min_value = f(min_x)\n",
    "\n",
    "print(f\"Minimum occurs at x = {min_x}\")\n",
    "print(f\"Minimum value = {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum occurs at x = 1.3423123924933694e-27 and y = 3.9663707936306647\n",
      "Minimum value = 10.094710265808493\n"
     ]
    }
   ],
   "source": [
    "e = 2.718281828459045\n",
    "\n",
    "def g(x, y):\n",
    "    return 3 * x**2 + 5 * (e**-y) + 10\n",
    "\n",
    "def dg_dx(x, y):\n",
    "    return 6 * x\n",
    "def dg_dy(x, y):\n",
    "    return -5 * (e**-y)\n",
    "\n",
    "def gradient_descent_2d(learning_rate, max_iterations):\n",
    "    x = 1.0\n",
    "    y = 1.0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        grad_x = dg_dx(x, y)\n",
    "        grad_y = dg_dy(x, y)\n",
    "        prev_x = x\n",
    "        prev_y = y\n",
    "        x = x - learning_rate * grad_x\n",
    "        y = y - learning_rate * grad_y\n",
    "\n",
    "        if ((x - prev_x)**2 + (y - prev_y)**2)**0.5 < 1e-6:\n",
    "            print(f\"Converged after {i+1} iterations\")\n",
    "            break\n",
    "\n",
    "    return x, y\n",
    "\n",
    "learning_rate = 0.01\n",
    "max_iterations = 1000\n",
    "min_x, min_y = gradient_descent_2d(learning_rate, max_iterations)\n",
    "min_value = g(min_x, min_y)\n",
    "\n",
    "print(f\"Minimum occurs at x = {min_x} and y = {min_y}\")\n",
    "print(f\"Minimum value = {min_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = -1.240692\n",
      "sigmoid(x) = 0.224316\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def gradient_descent_sigmoid(learning_rate, max_iterations):\n",
    "\n",
    "    xi = 1.0\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    def sigmoid_derivative(x):\n",
    "        sig = sigmoid(x)\n",
    "        return sig * (1 - sig)\n",
    "    for i in range(max_iterations):\n",
    "        gradient = sigmoid_derivative(xi)\n",
    "        xi_new = xi - learning_rate * gradient\n",
    "        if abs(gradient) < 1e-6:\n",
    "            print(f\"Converged after {i+1} iterations\")\n",
    "            break\n",
    "\n",
    "        xi = xi_new\n",
    "\n",
    "    return xi\n",
    "\n",
    "learning_rate = 0.01\n",
    "max_iterations = 1000\n",
    "min_x = gradient_descent_sigmoid(learning_rate, max_iterations)\n",
    "\n",
    "print(f\"x = {min_x:.6f}\")\n",
    "print(f\"sigmoid(x) = {1/(1 + math.exp(-min_x)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 1.9896587550255742, C = 0.030404521305361965\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent_linear_model(inputs, expected_outputs, learning_rate, num_iterations):\n",
    "    M, C = 0, 0\n",
    "    n = len(inputs)\n",
    "    for i in range(num_iterations):\n",
    "        grad_M = sum(-2 * x * (y - (M * x + C)) for x, y in zip(inputs, expected_outputs)) / n\n",
    "        grad_C = sum(-2 * (y - (M * x + C)) for x, y in zip(inputs, expected_outputs)) / n\n",
    "        M = M - learning_rate * grad_M\n",
    "        C = C - learning_rate * grad_C\n",
    "        if abs(grad_M) < 1e-6 and abs(grad_C) < 1e-6:\n",
    "            print(f\"Converged after {i+1} iterations\")\n",
    "            break\n",
    "\n",
    "    return M, C\n",
    "\n",
    "inputs = [1, 2, 3, 4]\n",
    "expected_outputs = [2, 4, 6, 8]\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "\n",
    "M, C = gradient_descent_linear_model(inputs, expected_outputs, learning_rate, num_iterations)\n",
    "print(f\"M = {M}, C = {C}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x = -1.60, f(x) = -40.60, f'(x) = 26.00\n",
      "Iteration 1: x = 7.55, f(x) = 197.35, f'(x) = -91.52\n",
      "Iteration 2: x = -858.40, f(x) = -22317.43, f'(x) = 8659.53\n",
      "Iteration 3: x = 1265029831.91, f(x) = 32890775630.67, f'(x) = -12650306903.12\n",
      "Iteration 4: x = -4048855683368040987719892992.00, f(x) = -105270247767569061282670706688.00, f'(x) = 40488556833680405479152418816.00\n",
      "Iteration 5: x = 132747663895560379390685320115646207514183660413405746239735203098413203015447085056.00, f(x) = 3451439261284570133757284994513199342038926040944856138604559505964468089437726703616.00, f'(x) = -1327476638955603632147173198252623307139746082016273420574485495740697143532809355264.00\n",
      "Iteration 6: x = -4678543339217819506657213367159102987107243120201274216005043431620135028306039605992472540317040111014367579117330688498735374561848577516276661636325884873626994607943932732171380132292365419381254142682217560731139831875759501782252559749045288960.00, f(x) = -121642126819663300813973441482432879294568336382822663283926003112134191510399882001099583844843316475095594494914624215769374803159187162944401341850193259358501181237864304855008301658200287770025997762710426574732390931307091042681465840244604534784.00, f'(x) = 46785433392178188707458027607887231500852446459602275827845308206212031057503248305220023199770674698865713229037333199789608810169609922683974755668979101380469267510761381140266219541522441059925931479794945603034153621294939014165424884259879911424.00\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     30\u001b[0m max_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(x0, learning_rate, epsilon, max_iterations)\u001b[0m\n\u001b[1;32m      9\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m iteration \u001b[38;5;241m<\u001b[39m max_iterations:\n\u001b[0;32m---> 12\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m \u001b[43mf_prime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(gradient) \u001b[38;5;241m<\u001b[39m epsilon:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m, in \u001b[0;36mf_prime\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_prime\u001b[39m(x):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m x\n",
      "\u001b[0;31mOverflowError\u001b[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 5 * x*4 + 3 * x*2 + 1\n",
    "\n",
    "def f_prime(x):\n",
    "    return 20 * x**3 + 6 * x\n",
    "\n",
    "def gradient_descent(x0, learning_rate, epsilon, max_iterations):\n",
    "    x = x0\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        gradient = f_prime(x)\n",
    "\n",
    "        if abs(gradient) < epsilon:\n",
    "            break\n",
    "\n",
    "        x = x - learning_rate * gradient\n",
    "\n",
    "        print(f\"Iteration {iteration}: x = {x:.2f}, f(x) = {f(x):.2f}, f'(x) = {gradient:.2f}\")\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    print(f\"\\nMinimum value found at x = {x:.2f}, f(x) = {f(x):.2f} after {iteration} iterations.\")\n",
    "    return x\n",
    "\n",
    "\n",
    "x0 = 1.0\n",
    "learning_rate = 0.1\n",
    "epsilon = 0.001\n",
    "max_iterations = 100\n",
    "\n",
    "gradient_descent(x0, learning_rate, epsilon, max_iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
